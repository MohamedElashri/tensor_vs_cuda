{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import GradScaler, autocast\n",
    "import pickle, os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Set up CIFAR-10 Dataset with Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='../data/train', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='../data/test', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN Model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Check if a GPU is available and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleCNN().to(device)  # Move model to the device\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = GradScaler()  # No need to specify device here\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    # Use tqdm for progress bar\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\", leave=False)\n",
    "    \n",
    "    # Iterate over the data\n",
    "    for i, (inputs, labels) in enumerate(progress_bar, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Enable autocasting for the forward pass\n",
    "        with autocast(device_type='cuda'):  # Specify the device type correctly\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Scales the loss, and calls backward()\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # scaler.step() unscales the gradients and calls or skips optimizer.step()\n",
    "        scaler.step(optimizer)\n",
    "        \n",
    "        # Updates the scale for next iteration\n",
    "        scaler.update()\n",
    "        \n",
    "        # define a new loss for the next iteration\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=f\"{running_loss / (i + 1):.4f}\")\n",
    "    \n",
    "    # close progress bar\n",
    "    progress_bar.close()\n",
    "    \n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 5.055\n",
      "Test Accuracy: 69.15%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model on Test Data\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move inputs and labels to the device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)  # Calculate loss\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get predicted class\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate average test loss and accuracy\n",
    "average_test_loss = test_loss / len(test_loader)\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f\"Test Loss: {average_test_loss:.3f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'simple_cnn_fp16.pth'\n"
     ]
    }
   ],
   "source": [
    "# 4. Export the Model and Save Validation Data\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), '../data/simple_cnn_fp16.pth')\n",
    "print(\"Model saved as 'simple_cnn_fp16.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data saved as 'validation_data.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save the validation data to a file for later inference benchmarking\n",
    "validation_data = []\n",
    "for images, labels in test_loader:\n",
    "    validation_data.append((images, labels))\n",
    "\n",
    "with open('../data/validation_data.pkl', 'wb') as f:\n",
    "    pickle.dump(validation_data, f)\n",
    "\n",
    "print(\"Validation data saved as 'validation_data.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PVfinderV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
